{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining with Pandas\n",
    "\n",
    "Joining allows you to combine `Series` and `DataFrame`s.\n",
    "\n",
    "## Import Pandas\n",
    "\n",
    "As usual, let's import Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate and Append\n",
    "\n",
    "## Concatenate\n",
    "\n",
    "`concat` sticks dataframes together, either on top of each other, or next to each other.\n",
    "\n",
    "Let's take a look at the [docs](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html) for `concat`, which says it will \"Concatenate pandas objects along a particular axis with optional set logic along the other axes.\":\n",
    "\n",
    "```python\n",
    "pandas.concat(objs, axis=0, join='outer', join_axes=None, \n",
    "              ignore_index=False, keys=None, levels=None, names=None, \n",
    "              verify_integrity=False, sort=None, copy=True)\n",
    "```\n",
    "\n",
    "Let's see it in action with two dataframes, `df1` and `df2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.DataFrame( {'letter': ['a', 'b'], 'number': [1, 2] })\n",
    "# df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = pd.DataFrame( [ ['c', 3], ['d', 4], ['e', 5] ], columns=['letter', 'number'] )\n",
    "# df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's stick the dataframes on top of each other using `concat`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's stick the dataframes **next** to each other using `concat`. We want it to concatenate along the columns of the table, so the `axis='columns'` kwarg will help us here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat([df1, df2], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append\n",
    "\n",
    "`append` is very similar to `concat`, except it limits itself to a specific case of `concat` -- specifically where `axis=0` (stack on top of each other) and `join=outer` (how to handle the axis of the second dataframe).\n",
    "\n",
    "Let's take a look at the [docs](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.append.html), which says `append` will \"Append rows of other to the end of caller, returning a new object\":\n",
    "\n",
    "```python\n",
    "DataFrame.append(self, other, ignore_index=False, verify_integrity=False, sort=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3 = df1.append(df2)\n",
    "# df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For almost all cases, `concat` can do all that `append` can do (and more), so we'll focus on `concat`.\n",
    "\n",
    "Also note that `append` is a `DataFrame` and `Series` method, whereas `concat` is a general pandas library function.\n",
    "\n",
    "Notice that in both cases of `concat` and `append`, the index was also simply stacked together. You can regenerate the index with `reset_index`, if you wish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3.reset_index(inplace=True, drop=True)\n",
    "# df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining\n",
    "\n",
    "## Join\n",
    "\n",
    "`join` allows us to combine two dataframes by using a matching column known as a `key`.\n",
    "\n",
    "With `join`, the `key` joining the table is always the `index` of the first table with (by default) the index of the second table. \n",
    "\n",
    "Let's take a look at the [docs](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html), which says `join` will \"Join columns with other DataFrame either on index or on a key column\":\n",
    "\n",
    "```python\n",
    "DataFrame.join(self, other, on=None, how='left', lsuffix='', rsuffix='', sort=False)\n",
    "```\n",
    "\n",
    "Let's take it out for a spin. First, create two dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.DataFrame( [ ['a', 1], ['b', 2], ['c', 3], ['d', 4] ], columns=['letter', 'number'] )\n",
    "# df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = pd.DataFrame( [ ['e', 5], ['f', 6] ], columns=['letter', 'number'] )\n",
    "# df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets `join` these two dataframes. Note that we will 'line up', the two dataframes based on their indicies.\n",
    "\n",
    "When joining dataframes where column names are not unique, we will need to supply a `lsuffix` or `rsuffix` kwarg.\n",
    "\n",
    "This is appended to the end of the column name of the returned, joined dataframe to differentiate and identify the source column. Here, we'll use `_df1` to identify that the column shown came from the `df1` dataframe, and `_df2` as a suffix to identify its origin as the `df2` dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.join(df2, lsuffix='_df1', rsuffix='_df2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we have joined the two dataframes on their indicies, which creates a null for rows of index 2 and 3 in the `_df2` values. This is expected and correct, as those indicies don't exist in `df2`.\n",
    "\n",
    "The default behavior of `join` is `left`. That means we keep everything from the left table, and disregard anything on the right table that doesn't have a matching `key`.\n",
    "\n",
    "If `df2` had more elements than `df1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = pd.DataFrame( [ ['e', 5], ['f', 6], ['g', 7], ['h', 8], ['Z', 9001] ], columns=['letter', 'number'] )\n",
    "# df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we join them together again,  you'll see that the `Z: 9000` data point will not be present in the joined table. As mentioned before, a `left` join keeps everything from the left table and disregards anything on the right table that doesn't have a matching `key`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.join(df2, lsuffix='_df1', rsuffix='_df2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.join(df2, lsuffix='_df1', rsuffix='_df2', how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Types\n",
    "\n",
    "We can change the join type with the `how` kwarg.\n",
    "\n",
    "For reference, here are the common types of joins. \n",
    "\n",
    "The type of join (**left**) we just performed above is the upper-left most figure. We'll briefly look at **inner** and **right** joins but other join types won't be covered in detail in this course unfortunately.\n",
    "\n",
    "<img src=\"assets/join_types.jpg\" width=\"500\" />\n",
    "\n",
    "## Merge\n",
    "\n",
    "Similar to `join` is `merge`. The difference between the two is the *keying behavior*. `merge` has a richer API (more functionality) and allows one to join on columns in the source dataframe *other than the index*.\n",
    "\n",
    "Because `merge` can effectively do everything that `join` can do, and more - at this beginner level it is recommended to use `merge` unless code brevity is the top concern. \n",
    "\n",
    "Let's take a look at the [docs](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.merge.html), which says `merge` will \"Merge DataFrame or named Series objects with a database-style join\":\n",
    "\n",
    "```python\n",
    "pandas.merge(left, right, how='inner', on=None, left_on=None, right_on=None, \n",
    "             left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), \n",
    "             copy=True, indicator=False, validate=None)\n",
    "```\n",
    "\n",
    "Note that `merge` comes in *both* a [`DataFrame` method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html) flavor as well as a [general function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.merge.html) flavor.\n",
    "\n",
    "Below, we'll be using the general function flavor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.merge(df1, df2, how='left', left_index=True, right_index=True, suffixes=('_df1', '_df2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we've achieved the same exact output as we did with `join`, but it took a little more explicit work. Let's run through the arguments for clarity:\n",
    "\n",
    "* `df1`: this is the first dataframe, and considered to be on the **left**\n",
    "* `df2`: this is the second dataframe, considered to be on the **right**\n",
    "* `how='left'`: this states the type of join; see the above diagram\n",
    "* `left_index=True`: this uses the index of `df1` as the join key for the left table\n",
    "* `right_index=True`: this uses the index of `df2` as the join key for the right table\n",
    "* `suffixes`: this places `_df?` after column names which came from `df?`\n",
    "\n",
    "How does the situation change if we use `how='right'`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.merge(df1, df2, how='right', left_index=True, right_index=True, suffixes=('_df1', '_df2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge on Non-Index Columns\n",
    "\n",
    "This brings us to our next point: merging on columns that are not the index columns. This is very common in SQL joins and this technique can be used to join just about any DataFrame.\n",
    "\n",
    "First, let's create some more realistic data - stocks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_name = pd.DataFrame({\n",
    "#     'Symbol': ['AMZN', 'DHR', 'DAL', 'AAPL'],\n",
    "#     'Name': ['Amazon', 'Danaher', 'Delta Airlines', 'Apple']\n",
    "# })\n",
    "\n",
    "# opening_price = pd.DataFrame({\n",
    "#     'Symbol': ['AAPL', 'DHR', 'DAL', 'AMZN'],\n",
    "#     'OpeningPrice': [217.51, 96.54, 51.45, 1703.34]\n",
    "# })\n",
    "\n",
    "# yearly_high = pd.DataFrame({\n",
    "#     'Symbol': ['DAL', 'AMZN', 'AAPL', 'DHR'],\n",
    "#     '52wkHigh': [60.79, 2050.49, 233.47, 110.11]\n",
    "# })\n",
    "\n",
    "# print(stock_name, opening_price, yearly_high, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's join the `opening_price` and `yearly_high` dataframes together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.merge(opening_price, yearly_high, on='Symbol')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the dataframes are not in any particular order. This is intentional. Because of this, notice that the dataframe on the left (`opening_price`) dictates the order of the dataframe on the right, `yearly_high`.\n",
    "\n",
    "In this particular case, we could also have omitted the `left_on` and `right_on` kwargs, as `Symbol` is the only common column between the two dataframes.\n",
    "\n",
    "Note that the shared key between the two dataframes is exempt from having a `suffix` applied to it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now it's your turn!\n",
    "\n",
    "* `merge` the `stock_name` and `opening_price` dataframes and inspect the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.merge(stock_name, opening_price, on='Symbol')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `merge` all three dataframes together and inspect the result (**Hint**: Remember that `merge` comes in two flavors!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.merge(stock_name, opening_price, on='Symbol') \\\n",
    "#   .merge(yearly_high, on='Symbol')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Example: Adventure Works\n",
    "\n",
    "<img src=\"assets/adventure_works_logo.png\" align=\"right\" />\n",
    "\n",
    "Here are data dictionaries for the data we'll be using:\n",
    "\n",
    "* [Products](https://www.sqldatadictionary.com/AdventureWorks2014/Production.Product.html)\n",
    "* [Product Subcategories](https://www.sqldatadictionary.com/AdventureWorks2014/Production.ProductSubCategory.html)\n",
    "* [Orders](https://www.sqldatadictionary.com/AdventureWorks2014/Sales.SalesOrderHeader.html)\n",
    "* [Line Items](https://www.sqldatadictionary.com/AdventureWorks2014/Sales.SalesOrderDetail.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# products              = pd.read_csv('data/product.csv')\n",
    "# product_subcategories = pd.read_csv('data/product_subcategories.csv')\n",
    "# orders                = pd.read_csv('data/orders.csv', nrows=100)\n",
    "# line_items            = pd.read_csv('data/line_items.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Product Tables\n",
    "\n",
    "It would appear that every product should have a `ProductSubCategory`, which makes sense: Each product is a type of a product (or what they chose to call `ProductSubCategory`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(products.shape)\n",
    "# products.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(product_subcategories.shape)\n",
    "# product_subcategories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do an \"Inner Join\" (the default) on the `products` and `product_subcategories` tables, with the `ProductSubcategoryID` key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', 30)\n",
    "\n",
    "# merged_products = pd.merge(products, product_subcategories, on='ProductSubcategoryID', suffixes=('_p', '_ps') )\n",
    "# print(merged_products.shape)\n",
    "# merged_products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Sales Orders and Sales Line Items Tables\n",
    "\n",
    "Note that each \"invoice\" (kept track of in `orders`) can have multiple \"line items\" (`line_items`). This makes it a \"one-to-many\" merge.\n",
    "\n",
    "* Do a 'left join\" on the `orders` and `line_items` tables -- the orders table is on the left\n",
    "* Because this is a \"one-to-many\" merge, you can optionally add a `validate=\"1:m\"` kwarg, see the [docs](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.merge.html)\n",
    "* Don't forget to check your data dictionaries if necessary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(orders.shape)\n",
    "# orders.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(line_items.shape)\n",
    "# line_items.head(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', 35)\n",
    "\n",
    "# full_orders = pd.merge(orders, line_items, how='inner', on='SalesOrderID')\n",
    "# print(full_orders.shape)\n",
    "# full_orders.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Sales Orders, Sales Line Items, and Products Tables\n",
    "\n",
    "* Join the `orders`, `line_items`, and `products` tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', 60)\n",
    "# fowmp = full_orders.merge(merged_products, how='left', on='ProductID')\n",
    "# print(fowmp.shape)\n",
    "# fowmp.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Finally, here's how to drop columns that you deem are not necessary for your analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_drop = ['RevisionNumber', 'OnlineOrderFlag', 'CustomerID', 'SalesPersonID', \n",
    "#                    'TerritoryID', 'BillToAddressID', 'ShipToAddressID', 'ShipMethodID', \n",
    "#                    'CreditCardID', 'CreditCardApprovalCode', 'CurrencyRateID', 'Comment', \n",
    "#                    'MakeFlag', 'FinishedGoodsFlag', 'SafetyStockLevel', 'ReorderPoint', \n",
    "#                    'Size', 'SizeUnitMeasureCode', 'WeightUnitMeasureCode', 'Weight',\n",
    "#                    'DaysToManufacture', 'ProductSubcategoryID', 'ProductModelID',\n",
    "#                    'SellStartDate', 'SellEndDate', 'DiscontinuedDate', 'ModifiedDate_p',\n",
    "#                    'ProductCategoryID', 'ModifiedDate_ps', 'ModifiedDate_x', \n",
    "#                    'ModifiedDate_y', 'LineItemID', 'ProductID', 'ModifiedDate_y', \n",
    "#                    'ProductLine', 'Class', 'Style']\n",
    "\n",
    "# fowmp.drop(columns_to_drop, axis='columns', inplace=True)\n",
    "# fowmp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
